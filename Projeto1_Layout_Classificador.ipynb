{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: João Pedro Reis Lima\r\n",
    "\r\n",
    "Nome: Lucas Gurgel "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "Carregando algumas bibliotecas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "source": [
    "%matplotlib inline\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import re \r\n",
    "import emoji\r\n",
    "from emoji import UNICODE_EMOJI\r\n",
    "from random import *\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from nltk.corpus import stopwords\r\n",
    "import nltk\r\n",
    "nltk.download('stopwords')\r\n",
    "from nltk.stem import RSLPStemmer\r\n",
    "nltk.download('rslp')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 972
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "source": [
    "print('Esperamos trabalhar no diretório')\r\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\lucas\\Downloads\\Projeto-1-CDADOS\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "source": [
    "filename = 'esquadrão suicida 2.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "source": [
    "dados = pd.read_excel(filename)\r\n",
    "dados.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to feliz q da p prestar atenção e gostar de vá...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>os roteirista de esquadrão suicida 2 devem ter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assistir esse esquadrão suicida 2 de marola</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e eu e gilson que fechamos a sala de cinema p ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>esquadrão suicida 2 é muito bom, amei o filme</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  relevancia\n",
       "0  to feliz q da p prestar atenção e gostar de vá...           1\n",
       "1  os roteirista de esquadrão suicida 2 devem ter...           0\n",
       "2        assistir esse esquadrão suicida 2 de marola           0\n",
       "3  e eu e gilson que fechamos a sala de cinema p ...           0\n",
       "4      esquadrão suicida 2 é muito bom, amei o filme           1"
      ]
     },
     "metadata": {},
     "execution_count": 975
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assisti esquadrão suicida 2 com um pouco de at...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vou ver esquadrão suicida 2 hj, vcs já viram?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@lsdcomixxx adm hj eu sonhei que ele tava no e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ranking personagens do esquadrão suicida:\\n\\n1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mano gloria groove no esquadrão suicida 2 fico...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  relevancia\n",
       "0  assisti esquadrão suicida 2 com um pouco de at...           0\n",
       "1      vou ver esquadrão suicida 2 hj, vcs já viram?           0\n",
       "2  @lsdcomixxx adm hj eu sonhei que ele tava no e...           0\n",
       "3  ranking personagens do esquadrão suicida:\\n\\n1...           1\n",
       "4  mano gloria groove no esquadrão suicida 2 fico...           1"
      ]
     },
     "metadata": {},
     "execution_count": 976
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "## Classificador automático de sentimento\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Relavante \r\n",
    "Comentários que demostravam alguma critica ao produto tais como: Se a pessoa gostou ou não da obra, o que ela sentiu(emoção), também consideramos personagens favoritos como algo relavante \r\n",
    "\r\n",
    "## Irrelevante\r\n",
    "Não consideramos comentarios de situações adversas sem relação direta com a criticidade da obra, tal como comentarios pessoais"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "______________\r\n",
    "\r\n",
    "### Limpando o Excel\r\n",
    "\r\n",
    "sinais de pontuação e diversos \r\n",
    "\r\n",
    "Letras minusculas\r\n",
    "\r\n",
    "Separação de emojis\r\n",
    "\r\n",
    "aplicando Stopwords\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "source": [
    "def cleanup(text):\r\n",
    "    punctuation = '[”@\\-/!.:?;,_°''\"|()#$%¨&*\\n+={}ªº><]'\r\n",
    "    pattern = re.compile(punctuation)\r\n",
    "    text_subbed = re.sub(pattern, '', text)\r\n",
    "    return text_subbed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "source": [
    "def minusculo(text):  # colocando em letra minuscula\r\n",
    "    return text.lower()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "source": [
    "base_prepo = nltk.corpus.stopwords.words('portuguese')\r\n",
    "def stopwords(lista):\r\n",
    "    listas = []\r\n",
    "    for word in lista:\r\n",
    "        if word not in base_prepo:\r\n",
    "            listas.append(word)\r\n",
    "    return listas           \r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "source": [
    "def removeradical(lista):\r\n",
    "    listanova = []\r\n",
    "    remove = RSLPStemmer()\r\n",
    "    for text in lista:\r\n",
    "        listanova.append(remove.stem(text))\r\n",
    "    return listanova"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "source": [
    "def separa_emoji(text):\r\n",
    "    pega = emoji.get_emoji_regexp().split(text)\r\n",
    "    trasforma= ' '.join(pega)\r\n",
    "    trasforma = trasforma.split()\r\n",
    "    for i,text in enumerate(trasforma):\r\n",
    "        if text in UNICODE_EMOJI['pt']:\r\n",
    "            trasforma[i]=UNICODE_EMOJI['pt'][text].replace(':','')\r\n",
    "        elif text in UNICODE_EMOJI['en']: \r\n",
    "            trasforma[i]= UNICODE_EMOJI['en'][text].replace(':','')\r\n",
    "        else:\r\n",
    "            continue\r\n",
    "    trasforma=' '.join(trasforma)  \r\n",
    "    return trasforma"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "source": [
    "def limpatudo(text):  # função que aplica as limpezas anteriores \r\n",
    "    tira_pontuacao = cleanup(text)\r\n",
    "    tudo_minusculo = minusculo(tira_pontuacao)\r\n",
    "    limpoemoji = (separa_emoji(tudo_minusculo))\r\n",
    "    lista_limpo = limpoemoji.split()\r\n",
    "    Semstopwords = stopwords(lista_limpo)\r\n",
    "    semstemming = removeradical(Semstopwords)\r\n",
    "    limpo = \" \".join(semstemming)\r\n",
    "    return limpo\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "source": [
    "def lista(df):   # Função que separa as Frases em palavras\r\n",
    "    listaf = []\r\n",
    "    lista = df.values.tolist() \r\n",
    "    for i in lista:\r\n",
    "        for palavra in i.split():\r\n",
    "            listaf.append(palavra)\r\n",
    "    return listaf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "______________________________\r\n",
    "## Começando o Classificador Naive-Bayes\r\n",
    "Vamos separar as variaveis necessárias para a implementação do naive bayers assim como filtrar e aplicar a funcao de limpeza na nossa base de dados\r\n",
    "\r\n",
    "Considerando apenas as mensagens da planilha Treinamento:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "source": [
    "#Transformando palavras em variáveis categóricas:\r\n",
    "dados['Treinamento'] = dados['Treinamento'].astype('category')\r\n",
    "test['Teste'] = test['Teste'].astype('category')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "source": [
    "#aplicando a limpeza \r\n",
    "dados['Treinamento']=dados['Treinamento'].apply(limpatudo)\r\n",
    "test['Teste']=test['Teste'].apply(limpatudo)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "source": [
    "#Separando a Planilha de Treinamento de acordo com a relevancia\r\n",
    "\r\n",
    "IR = dados['relevancia'] == 0\r\n",
    "R = dados['relevancia'] == 1\r\n",
    "\r\n",
    "dados_r = dados.loc[R,:]\r\n",
    "dados_ir = dados.loc[IR,:]\r\n",
    "\r\n",
    "dados_r.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to feliz q p prest atenç gost vári person esqu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>esquadr suic 2 bom ame film</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>henriquenarizz kkkkkk amig pi esquadr suic 2 t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ruanfalc dccomic tô p assist esquadr suic 2 ag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ei gost esquadr suic 2 opin import</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Treinamento  relevancia\n",
       "0   to feliz q p prest atenç gost vári person esqu...           1\n",
       "4                         esquadr suic 2 bom ame film           1\n",
       "5   henriquenarizz kkkkkk amig pi esquadr suic 2 t...           1\n",
       "8   ruanfalc dccomic tô p assist esquadr suic 2 ag...           1\n",
       "16                 ei gost esquadr suic 2 opin import           1"
      ]
     },
     "metadata": {},
     "execution_count": 986
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "source": [
    "#Aplicando a separação das frases no dataframe de treinamento \r\n",
    "pdr = lista(dados_r.Treinamento)   \r\n",
    "pdir = lista(dados_ir.Treinamento)\r\n",
    "\r\n",
    "#Transformando o em pd.series\r\n",
    "pdrc = pd.Series(pdr) \r\n",
    "pdirc = pd.Series(pdir) \r\n",
    "\r\n",
    "#Extraindo a frequência absoluta\r\n",
    "fpdr=pdrc.value_counts()\r\n",
    "fpdir=pdirc.value_counts()\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "suic       138\n",
       "2          138\n",
       "esquadr    128\n",
       "film        40\n",
       "bom         25\n",
       "          ... \n",
       "nad          1\n",
       "far          1\n",
       "cadel        1\n",
       "começ        1\n",
       "promoç       1\n",
       "Length: 523, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 987
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "source": [
    "# Colocando as palavras em um Banco de dados e uma lista total\r\n",
    "listadr = pdrc.tolist()\r\n",
    "listadir = pdirc.tolist()\r\n",
    "\r\n",
    "#criando a lista total\r\n",
    "lista_total2 = pd.Series(listadr + listadir)\r\n",
    "\r\n",
    "#criando o banco de dados\r\n",
    "Banco_de_dados=set(listadr+listadir)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____________\r\n",
    "## Probabilidades Iniciais\r\n",
    "Aqui nós iremos calcular a probabilidade de palavras relevantes e irrelevantes no conjunto total\r\n",
    "\r\n",
    "A soma entre as probabilidades de ser relevante ou irrelevante tem que ser igual a 1\r\n",
    "\r\n",
    "## P(relevante) + P(irrelevante) = 1\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "source": [
    "# probabilidade de ser relevante:\r\n",
    "pr = len(listadr)/len(lista_total2)\r\n",
    "# probabilidade de ser irrelevante:\r\n",
    "pi = len(listadir)/len(lista_total2)\r\n",
    "print(pr+pi)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "______________\r\n",
    "## Suavização de Laplace\r\n",
    "\r\n",
    "Técnica que é ultilizada para garantir que o naive-bayes seja ultilizado como palavra fora do banco de dados, ou seja, evitar que a probabilidade seja 0\r\n",
    "\r\n",
    "Aplicando a suavização:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "source": [
    "# função que aplica o laplace\r\n",
    "def laplace(freqabsoluta,conjunto):\r\n",
    "    return (freqabsoluta+1)/((conjunto)+len(Banco_de_dados))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "source": [
    "# função que determina a probabilidade relevante dado a uma frase\r\n",
    "def prob_R(text):\r\n",
    "    Prob1 = 1\r\n",
    "    for i in text.split():\r\n",
    "        if i in fpdr:\r\n",
    "\r\n",
    "            Alaplace_relevante = laplace(fpdr[i], pr)\r\n",
    "        \r\n",
    "            Prob1 *= Alaplace_relevante\r\n",
    "        else:\r\n",
    "            Alaplace_relevante = laplace(0, pr)\r\n",
    "        \r\n",
    "            Prob1 *= Alaplace_relevante\r\n",
    "    return Prob1\r\n",
    "\r\n",
    "print(prob_R('assistir esse esquadrão suicida 2 de marola'))\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.293083860697365e-20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "source": [
    "# função que determina a probabilidade irrelevante dado a uma frase\r\n",
    "def prob_I(text):\r\n",
    "    Prob2 = 1\r\n",
    "    for i in text.split():\r\n",
    "        if i in fpdir:\r\n",
    "\r\n",
    "            Alaplace_irrelevante = laplace(fpdir[i], pi)\r\n",
    "        \r\n",
    "            Prob2 *= Alaplace_irrelevante\r\n",
    "        else:\r\n",
    "            Alaplace_irrelevante = laplace(0, pi)\r\n",
    "        \r\n",
    "            Prob2 *= Alaplace_irrelevante\r\n",
    "    return Prob2\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "source": [
    "# fazendo a comparação das probabilidades para delvolver se é relevante ou não\r\n",
    "def probabilidades(text):\r\n",
    "    if prob_R(text)*pr > prob_I(text)*pi:\r\n",
    "        return 1\r\n",
    "    else:\r\n",
    "        return 0\r\n",
    "\r\n",
    "print(probabilidades('vi esquadrão suicida 2 hj com minhas irmã ')) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "source": [
    "dados['Classificado'] = dados.Treinamento.apply(probabilidades)\r\n",
    "dados.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Classificado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to feliz q p prest atenç gost vári person esqu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roteir esquadr suic 2 dev ter beb um 10 shot t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assist esquadr suic 2 marol</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gilson fech sal cinem p assist esquadr suic 2 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>esquadr suic 2 bom ame film</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  relevancia  Classificado\n",
       "0  to feliz q p prest atenç gost vári person esqu...           1             1\n",
       "1  roteir esquadr suic 2 dev ter beb um 10 shot t...           0             0\n",
       "2                        assist esquadr suic 2 marol           0             0\n",
       "3  gilson fech sal cinem p assist esquadr suic 2 ...           0             0\n",
       "4                        esquadr suic 2 bom ame film           1             1"
      ]
     },
     "metadata": {},
     "execution_count": 994
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "### Verificando a performance do Classificador\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "source": [
    "#Aqui nos verificamos a acuracia do nosso modelo para a base de treinamento\r\n",
    "\r\n",
    "dadossepara1=dados.loc[(dados['Classificado']==1)&(dados['relevancia']==1),:]\r\n",
    "dadosverdadeiro1=dadossepara1.shape[0]\r\n",
    "dadossepara2=dados.loc[(dados['Classificado']==0)&(dados['relevancia']==0),:]\r\n",
    "dadosverdadeiro2=dadossepara2.shape[0]\r\n",
    "soma1 = dadosverdadeiro1 + dadosverdadeiro2\r\n",
    "score2=soma1/dados.shape[0]\r\n",
    "print(score2*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "95.33333333333334\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "source": [
    "# aplicando a função do naive-bayes na base de test\r\n",
    "test['Classificado']=test.Teste.apply(probabilidades)\r\n",
    "test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>Classificado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assist esquadr suic 2 pouc atras pacific pod v...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vou ver esquadr suic 2 hj vc vir</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsdcomixxx adm hj sonh tav esquadr suic 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ranking person esquadr suicida1 bloodsport2 pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man glor groov esquadr suic 2 fic mto bom</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  relevancia  Classificado\n",
       "0  assist esquadr suic 2 pouc atras pacific pod v...           0             0\n",
       "1                   vou ver esquadr suic 2 hj vc vir           0             0\n",
       "2          lsdcomixxx adm hj sonh tav esquadr suic 2           0             0\n",
       "3  ranking person esquadr suicida1 bloodsport2 pe...           1             0\n",
       "4          man glor groov esquadr suic 2 fic mto bom           1             0"
      ]
     },
     "metadata": {},
     "execution_count": 996
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "source": [
    "#Aqui nos verificamos a acuracia do nosso modelo para a base de Teste\r\n",
    "\r\n",
    "testsepara1=test.loc[(test['Classificado']==1)&(test['relevancia']==1),:]\r\n",
    "testverdadeiro1=testsepara1.shape[0]\r\n",
    "testsepara2=test.loc[(test['Classificado']==0)&(test['relevancia']==0),:]\r\n",
    "testverdadeiro2=testsepara2.shape[0]\r\n",
    "soma = testverdadeiro1 + testverdadeiro2\r\n",
    "score=soma/test.shape[0]\r\n",
    "print(score*100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "78.5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "source": [
    "#Verificando a performance com as porcentagens de Verdadeiro positivoS, verdadeiro negativo e etc\r\n",
    "pd.crosstab(test['Classificado'], test['relevancia'], normalize=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>relevancia</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificado</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075</td>\n",
       "      <td>0.285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "relevancia        0      1\n",
       "Classificado              \n",
       "0             0.500  0.140\n",
       "1             0.075  0.285"
      ]
     },
     "metadata": {},
     "execution_count": 998
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Verdadeiro Positivo (relevantes classificados como relevantes): 28,5%\r\n",
    "\r\n",
    "## Verdadeiro Negativo (irrelevantes classificadas como irrelevantes): 50%\r\n",
    "\r\n",
    "## Falso Positivo (relevantes classificadas como irrelevantes): 14%\r\n",
    "\r\n",
    "## Falso Negativo (irrelevantes classificadas como relevantes): 7,5%"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "### Concluindo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dado o exposto, percebe-se que o nosso modelo baseado no Naive Bayes, podemos concluir a partir das respectivas porcentagens do verdadeiro positivo e verdadeiro negativo: 28,5% e 50%, as quais juntas somam 78,5% de acurácia, isso mostra que o nosso modelo é eficiente. Entretanto, os respectivos valores de falso positivo e negativo: 14% e 7,5%, ainda possuem altas taxas, isso ocorre por vários motivos, tal como a baixa variedade de palavras no banco de dados, o que faz com que palavras que possuem similaridade, as que são classificadas como relevante e irrelevante, não estão na base de dados, mesmo possuindo semântica e significados análogos e que no cálculo suas probabilidades não são levadas em consideração(são nulo/0). Outro fator importante na análise e que também confirma o que foi, anteriormente, visto é a diferença entre os percentuais de acurácia entre a base de treinamento e teste, que é de cerca de de 16,8%, isso acontece, pois o tamanho da base de dados é diferente e isso implica na acurácia na base Teste.    \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Além disso, nosso modelo na maioria das vezes não apresenta problema com as palavras de dupla negação ou sarcasmo,mas mesmo assim, nossa função não leva em consideração o real sentido da palavra e sim somente sua probabilidade, o que faz com que possa ter certos erros, por exemplo: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "source": [
    "# 1 = relevante\r\n",
    "# 0 = irrelevante\r\n",
    "\r\n",
    "\r\n",
    "print(probabilidades('esquadrão suicida 2 é tão ruim que é bom')) \r\n",
    "print(probabilidades('Começou esquadrão suicida 2 e o filme não foi nada demais')) #Fase criada para titulo de demonstração do problema (dupla negação)\r\n",
    "print(probabilidades('esquadrão suicida 2 é tão ruim quanto assistir esquadrão suicida 1 2 vezes')) #Fase criada para titulo de demonstração do problema (sarcasmo)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos concluir que nas frases anteriores, o nosso sistema ainda comete erros, porém em algumas frases pode ser visto que ele acerta na classificação, visto que é uma critica ao produto, ou seja, é relevante."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "____________\r\n",
    "## Plano de expansão e por que devem financiar nosso projeto\r\n",
    "\r\n",
    "Portanto, eles devem continuar financiando nosso projeto, visto que com melhorias nesses problemas vistos anteriormente, podemos desenvolver um sistema melhor, com uma melhor acurácia, o qual poderia ser implementado em outras situações, um exemplo disso seria a propia empresa da DC com a nossa análise de dados verificar como os fãs/midia está comentando sobre o filme, o que pode ser interpretado como um potencial para analisar seu produto ou ate coletar informações críaticas para futuros projetos se baseando na opinião geral. Dessa forma, com um maior financiamento podemos tornar nosso modelo mais eficiente com novas funções."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PORQUÊ NÃO PODE USAR O PRÓPRIO CLASSIFICADOR PARA GERAR MAIS AMOSTRAS DE TREINAMENTO?\r\n",
    "Como já foi dito anteriormente, o nosso modelo não entende o real sentido da palavra em seus diferentes contextos, logo aumentar o número de palavras só acarretaria em uma menor porcentagem na taxa de acurácia, além de que o erro poderia se propagar durante a reprodução de mais amostras.\r\n",
    "\r\n",
    "## Diferente cenários para Naives Bayes fora do contexto do projeto. \r\n",
    "1º - Podemos usar o nosso sistema para a detecção de emails, podendo classifica-los entre aqueles que são relevantes ou não, podendo , aqueles que não são relevantes, enviados para a caixa de spam.\r\n",
    "\r\n",
    "2º - Outra situação bastante útil, seria analisar textos em redes sociais, onde o sistema detectaria se tal mensagem feita por uma pessoas demonstra felicidade ou tristeza, tal feito ajudaria na descoberta de possíveis problemas que a pessoa poderia esta passando.\r\n",
    "\r\n",
    "3º - Outra, seria em prever se vai chover ou não no próximo dia, de acordo com as medições no dia de hoje, analisando a umidade, temperatura, por exemplo.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sugestões de melhorias reais:\r\n",
    "TF-IDF: Um método onde entendemos a importância de uma palavra, em decorrência de sua aparição. Para fazer tal cálculo, precisamos da frequência da palavra em um documento, e sua frequência inversa do documento (OBS: quanto mais proximo de 0 for esse valor, significa que a mesma é comum, mais perto de 1 , diz que a mesma não é comum), com isso podemos saber se aquela palavra é comum ou específica naquele documento. Após a multiplicação, podemos obter o resultado, quanto maior for o valor, sabemos que a palavra é relevante.\r\n",
    "\r\n",
    "N-Grams: Diferentemente do método que nós usamos, o N-Grams considera a frase completa, por meio de gramas, logo não precisavamos \"quebra-las\", tal método pode ser implementado usando sua função 'ngram' através da biblioteca nltk ou bigrams que pode ser importada da mesma biblioteca, porém essa última tem um certo limite de gramas que podem ser utilizados, diferentemente da ngram, devendo ter cuidado para não ter uma escassez de dados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\r\n",
    "\r\n",
    "Utilizaremos o sklearn com a função train_test_split\r\n",
    "\r\n",
    "A função divide o conjunto dado em uma quantidade que podemos escolher para separar entre teste e treinamento que escolhermos, nesse caso vamos separar 200 pro teste e 300 para o treinamento\r\n",
    "\r\n",
    "Assim sendo, aqui o objetivo é avaliar como os tweets contidos na base de dados\r\n",
    "treinamento pode interferir numa melhor ou não tão boa classificação das mensagens\r\n",
    "contidas na base de teste.\r\n",
    "\r\n",
    "guardaremos os percentuais de acertos (= % de positivos verdadeiros + % de\r\n",
    "negativos verdadeiros)\r\n",
    "\r\n",
    "Vamos Repitir o processo acima 100 vezes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "source": [
    "#lendo novamente os arquivos\r\n",
    "test_novo = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "dados_novo = pd.read_excel(filename, sheet_name = 'Treinamento')\r\n",
    "\r\n",
    "#Concatenando as planilhas do excel tem que mudar para o mesmo nome da coluna\r\n",
    "xaropinho = dados_novo.rename(columns={'Treinamento':'Frases'})\r\n",
    "xaropinha = test_novo.rename(columns={'Teste':'Frases'})\r\n",
    "\r\n",
    "junta = pd.concat([xaropinho,xaropinha], ignore_index=True)\r\n",
    "junta['Frases']=junta['Frases'].apply(limpatudo)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "source": [
    "lista_score=[]\r\n",
    "for i in range(0,100):\r\n",
    "    X_dados,X_test = train_test_split(junta,train_size=0.6,random_state=None) # aplicando a função e separando as bases\r\n",
    "    # criamos uma copia para evitar erros\r\n",
    "    X_dados = X_dados.copy()\r\n",
    "    X_test = X_test.copy()\r\n",
    "\r\n",
    "    #separamos o que é relevante ou irrelevante\r\n",
    "    X_dadosIr = X_dados['relevancia'] == 0\r\n",
    "    X_dadosR = X_dados['relevancia'] == 1\r\n",
    "\r\n",
    "    X_dados_r = X_dados.loc[X_dadosR,:]\r\n",
    "    X_dados_ir = X_dados.loc[X_dadosIr,:]\r\n",
    "\r\n",
    "    #aplicamos a função para separar as frases\r\n",
    "    X_dadosr = lista(X_dados_r.Frases)   \r\n",
    "    X_dadosir = lista(X_dados_ir.Frases)\r\n",
    "    \r\n",
    "    #Transformando o em pd.series\r\n",
    "    X_dadosrC = pd.Series(X_dadosr) \r\n",
    "    X_dadosirC = pd.Series(X_dadosir) \r\n",
    "\r\n",
    "    # extraindo a frequência absoluta\r\n",
    "    fpdr=X_dadosrC.value_counts()\r\n",
    "    fpdir=X_dadosirC.value_counts()\r\n",
    "\r\n",
    "    # Colocando as palavras em um Banco de dados e uma lista total\r\n",
    "    X_dadosr = X_dadosrC.tolist()\r\n",
    "    X_dadosir = X_dadosirC.tolist()\r\n",
    "\r\n",
    "    #criando a lista universo e criando a base de dados\r\n",
    "    listaX_dados = pd.Series(X_dadosr + X_dadosir)\r\n",
    "\r\n",
    "    Banco_de_dados=set(X_dadosr+X_dadosir)\r\n",
    "\r\n",
    "    # probabilidade de ser relevante:\r\n",
    "    pr = len(X_dadosr)/len(listaX_dados)\r\n",
    "    # probabilidade de ser irrelevante:\r\n",
    "    pi = len(X_dadosir)/len(listaX_dados)\r\n",
    "\r\n",
    "    #ultilizado a função para aplicar o naive-bayes\r\n",
    "    X_dados['Nova Classificação'] = X_dados.Frases.apply(probabilidades)\r\n",
    "    X_test['Nova Classificação'] = X_test.Frases.apply(probabilidades)\r\n",
    "    \r\n",
    "    # obtendo as taxes de verdadeiro positivo e negativo e colocando em um lista os scores\r\n",
    "    X_testsepara1=X_test.loc[(X_test['Nova Classificação']==1)&(X_test['relevancia']==1),:]\r\n",
    "    X_testverdadeiro1=X_testsepara1.shape[0]\r\n",
    "    X_testsepara2=X_test.loc[(X_test['Nova Classificação']==0)&(X_test['relevancia']==0),:]\r\n",
    "    X_testverdadeiro2=X_testsepara2.shape[0]\r\n",
    "    soma = X_testverdadeiro1 + X_testverdadeiro2\r\n",
    "    score=soma/X_test.shape[0]\r\n",
    "\r\n",
    "    \r\n",
    "    lista_score.append(score*100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "source": [
    "faixa=np.arange(63, 85, 0.8)\r\n",
    "plt.figure(figsize=(10, 5))\r\n",
    "plt.hist(lista_score, bins=faixa, edgecolor='darkblue', color='cyan', alpha=0.6, density=True)\r\n",
    "plt.title('Histograma de percentuais de acertos')\r\n",
    "plt.ylabel('Densidade')\r\n",
    "plt.xlabel('Score')\r\n",
    "plt.show()\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "source": [
    "media=sum(lista_score)/len(lista_score)\r\n",
    "print(media)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "74.74\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos concluir que quando o classificador é feito em uma única divisão entre treinamento e teste, o modelo pode assumir valores bem distintos, o que tem como consequência no campo da análise, uma mitigação na sua credibilidade, por isso é de extrema importância que seja feita uma análise de dados considerando as possíveis variações de resultados, como visto, em decorrer dos scores obtidos 100X. Em suma, percebe-se que é uma desvantagem fazer uma única divisão da base de dados, pois não retornará a melhor acurácia do modelo. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "## Aperfeiçoamento:\r\n",
    "\r\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\r\n",
    "\r\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\r\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\r\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\r\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\r\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\r\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\r\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ],
   "metadata": {},
   "attachments": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "## Referências"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\r\n",
    "\r\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://monkeylearn.com/blog/what-is-tf-idf/\r\n",
    "--\r\n",
    "https://sebastianraschka.com/Articles/2014_naive_bayes_1.html #n-grams\r\n",
    "--\r\n",
    "https://qastack.com.br/programming/17531684/n-grams-in-python-four-five-six-grams\r\n",
    "--\r\n",
    "https://qastack.com.br/programming/5486337/how-to-remove-stop-words-using-nltk-or-python #stop words\r\n",
    "--\r\n",
    "https://www.programcreek.com/python/?CodeExample=remove+emoji #emoji\r\n",
    "--\r\n",
    "https://blog.geekhunter.com.br/mineracao-de-texto-python-para-descobrir-emocoes/ #limpeza"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "978d606978bb26dc1196d980de5f982f9f8ebb0565a7cd0735526ac935a81f1b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}